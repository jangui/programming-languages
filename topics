## lambda calculus ##
  -functional language (contrary to imperative)
    -no mutable variables or stateful operations
    -everything is done through recursion

## church numbers ##

## types ##
  -static typing
    -compile time type check
    -varibles are composed of a type, name, and have a mem addr
    -ex: C++

  -dynamic typing
    -runtime type check
    -variables have a name and value
      -the value carries the type and has a mem addr
    -ex: python

  -strongly typed vs weakly typed
    -presence or absensce of:
      -type safety
      -memory safety
      -static type checking
      -dynamic type checking


  -types are sets of values
    -subtyping is when children are in the set of values of parent type
    -type synonims are not new types but aliases
      -ex: typedef in C
      -ex: type in Haskell
        -data keyword makes actual new type, not synonym
 
  -structural typing vs nominal typing
  struct A {int x; string z;}
  struct B {int x; string z;}
    -structural typing A and B are the same
    -nominal typing A and B are different
      -ex: C++

## haskell polymorphism ##
functions that can work with any given type
length: [a] -> Int
         ^type variable

types can also be polymorphic
data Tree a = Node a (Tree a) (Tree a) | Leaf

## haskell higher-order functions ##
  -map : (a -> b) -> [a] -> [b]
  -filter : (a -> Bool) -> [a] -> [a]
  -foldl : (b -> a -> a) -> b -> [a] -> b

## haskell data types ##
 -data keyword makes actual new type

  data Opinion = Agree | Disagree | Perhaps
                  deriving Show
  Agree, Disagree & Perhaps are constructors 

  data Person = Person String Int | Embryo
       ^type    ^      ^field ^field     ^constructor w/out fields
                ^constructor

       type Person has 2 constructor: Person and Embryo

  -can be used to return different data types
    -Either a b = Left a | Right B
      -ex: somefunc: Int -> Either String Char
  -can be used to provide error checking
    -Maybe a = Just a | Nothing
      -ex: somefunc: a -> Maybe a

## generics (boxing, monomorphization) & type safety ##
type safety: the prevention of type errors (which are runtime errors)

Monomorphization example w/ C++
C++: templates functions are recompliled for each type that uses it
     this differs type checking till after template expansion
     causes for bloated executables if template is constantly copy pasted
     causes for slower compilation because added time expanding templates

Monomorphization in C is usually done with macros (becomes very similar to how templates are implemented in C++)

Boxing example w/ C
C: to achieve generics we create structs&functions that operate on void pointers and use type casting.

ex: instead of creating a link list of ints, we make a link list of void pointers
    -benefits
      -no need to copy paste definition of function/data struct
        -ex: we can make link list of int pointers or string pointers, etc
    -downfall
      -loss of type safety (no more nice compile time errors )
        -ex: link list can become mix of int and string pointers & etc
        -programmer has to be in charge of proper type casting
          -ex: outputting is dependent of type, proper cast needed
          -can lead to undifined behavior or runtime errors
      -slower because using pointers

**note boxing's loss of type safety can be fixed w/ type erasure
given the following C++ code:

template <class T>
class Foo {
  T member;
  T function(T x);
};

now image that C++ used boxing instead of monomorphization
this means templates would not be instantiated for each class,
but a void pointer would be used for type T. Thus code doesn't get reused, causing bloat
however, to gain type safety type erasure is done
basically if we have:
Foo<int> iFoo;
iFoo.function(3);
the compiler will first do type checking using Foo<int>.
once type checking is done (and succesfully passed) the compiler erases the types, allowing for void pointers to be used, and templates not having to be expanded for each type

**type erasure broken in examples like Java's covarient arrays

## haskell typeclasses ##
typeclasses in haskell allow it to be strongly typed
  this allows generics funcs to be constrained by typeclasses

for example, to use == function, type must be in the Eq typeclass
for a type to be in the Eq typeclass the type must have the == operator declared so we create an instace of it

data Tree a = Node a (Tree a) (Tree a) | Leaf
instance Eq a => Eq (Tree a) where
  Leaf == Leaf = True
  (Node v l r) == Leaf = False
  Leaf == (Node v l r) = False
  (Node v1 l1 r1) == (Node v2 l2 r2) =
    v1 == v2 && l1 == l2 && r1 == r2 

adding Tree into functor typeclass
instance Functor Tree where
  fmap f (Node v l r) = mapTree f (Node v l r)
  fmap f Leaf = Leaf

mapTree :: (a->b) -> Tree a -> Tree b
mapTree func (Node val left right) = Node (func val) (mapTree func left)        (mapTree func right)
mapTree _ Leaf = Leaf

adding Tree into Show typeclass
instance Show a => Show (Tree a) where
  show mytree = printTree mytree 0

## covariance & contravarience ##
covariance: T is coverient iff
                T<B> is a subtype of T<A>
              & B is a subtype of A

ex: Arrays in C++
class A {};
class B : pulic A {};

void wantsA(A a); 
^can call with A or B
void wantsA(A a[]); 
^can call with array of A or array of B

Not covarient: vector in C++
wantsA(vector<A> a);
can only be called with vector of A
thats why we used vectors of pointers when doing polymorphism

contravarience: T is contravarience iff
                T<A> is a subtype of T<B>
              & B is a subtype of A

why we want a covarient and a contravarient type? (Java)
if we want to add things to the collection, it must be contravarient (? super a)
why? an array of X can contain subtypes of X but not supertypes
if we have a function that takes array of A, because array is contravarient, we can pass an array of B to the func. however, during compile time, we don't know the runtime type, so if we try adding an A object to the array, we get a runtime error if we try adding it to an array of Bs. Thus, doing a compile time check for things like these saves our ass

if we want to display, we need covarience, because we need garenties that what we are displaying exists.  ( ? extends A)
for example if we want an array of As we could also pass array of Bs. All B object derive from A so we can be assured that anything of an A we try to display, a B will have. However if we have a contravarient type, we cant try to display B's things because if an A gets passed thers no garentees they have the same stuff

**in C++ an array of X can't contain subtypes of X

## tail-call recursion ##
tail-call recursion: recursing as the last step in recursive func
                     this allow to dismantel stack frame of caller
                     this allows for recursion to go on infinetely bcs
                     stack space never gets fully used

**not all recursive functions can be written as tail call recursive

**not all languages support tail call recursion (python doesnt, haskell does)

example:
**note written in python although tail call recursion not supported

TAIL CALL RECURSIVE:
  def mystery(lst, lst2=[]):
    if len(lst) < 2:
      return (lst2 + lst)
    lst2 = lst2 +[lst[1]] + [lst[0]]
    return mystery(lst[2:], lst2)

NOT TAIL CALL RECURSIVE: 
  def mystery(lst):
    if len(lst) < 2:
      return lst
    return [lst[1]] + [lst[0]] + mystery(lst[2:])

# purity, effect & state ##

Effect: something that changes the state of the system
        ex timeline: old state -> call effectful func -> new state 

Purity: a function is pure if it does not alter its arguments
        pure functions have no effect

the state of the system is anything that can be changed. your display has a state, which is usually changing and can be changed. files have a state. other hardware devices as well. etc.

## lazy evaluation ##
how haskell implements infinite data types

infinite data types are only expanded as far out as they need to be because they are defined recursively

-ex: an inifinite list of all integers starts at 1 and the next number is the last plus 1

-ex: data Stream a = Chunk a (Stream a)
  -defined recursively

## monads ##
type class with bind function defined


## kinds ##
-types of types

## value types ##
example in haskell:
data Nat = Zero | Succ Nat
type Zero = Zero
type One = Succ Zero
type Two = Succ One


## small talk  / pharo ##
object oriented language
everything is a method

use "^" to return

kinds of methods
  unary
  binary
  keyword
^this is also order of precedence (unary first)

unary:
  3 factorial.

binary: 
  3 + 4.

keyword:
  3 ifTrue: [bc]


Block Closuers
[ args | body ].

Vars
  |myvar| (init to 0)
  myvar := 1.

Defining Classes
When defined, classes are instances of "class" type
to get instance of class, you need to use the "new" method.

aFoo := Foo new.

## Memory Structure of Classes ##
classes are basically represented like structs in memory

methods are function pointers

inheritance = copy parent struct and extend with your own things


address 0 of the struct is the Virtual Method Table (VMT) pointer
  pointer to another struct (VMT) where function pointers to methods are
  only non virtual methods are in VMT, (useful for inheritance)

  if a method is not virtual, it gets stored sequencially, not in VMT

Non Virtual Methods are faster (address known statically)
Virtual Methods can be overwritten and need to be checked in runtime

There is 1 VMT per class
  constructor will init class to point to correct VMT addr
    happens at end of constructor
      calls to virtual methods in constructor will call parent's methods
        generally avoid virtual calls in const / deconstr

Constructors in C++
  init vars
  init ancestor vars (call parent constr) (sets up VMT for par)
  run any constructor code
  setup VMT

  
## Javascript Objects ##
js objects are basically like a map (dict)
object has labels which hold vals of vars or method's func ptrs

we can define a normal function to be used a a constructor by calling it using the "new" keyword

ex:

pet = new Animal(4);

function Animal(x) {
  this.legs = x;
  this.isDead = false;
}

Animal.prototype.kill = function() {this.isDead = true;}


"new" will treat a function as a constructor and return an instance

objects (maps in js) have a label called prototype
prototype works like VMT in c++
prototype is an object that holds funcs

pet = new Animal(4);

pet obj
  legs ----> 4
  isDead --> false
  __proto__  ----> {kill, proto --> {}}


if we did pet.kill() we'd search in proto to see if theres a kill method
then we would search proto's proto obj

to get inheritance, what basically happens in child's constructor will create an instance of parent inside childs proto

Child.prototype = new Parent();

child will now have all of parents members and parents proto


## Prolog ##
programming language based on predicate logic 
works just as horne clauses do

horne clause:
  statement that is true if all statements it is composed of are true

ex: L1 & L2 => L
L is true if L1 and L2 are true

=> A
A is a "fact" always true (no reqs)

in prolog:
L :- L1, L2.

prolog has atoms and Variables
Variables start with capitols, and can be unified to other values
atoms are lowercase, or nums, and are set values

legs(cow, 4). (fact bcs cows and 4 are atoms, thus true).
edible(cow).

legs(X, 4). (X = cow) X, var, unifies to cow
legs(cow, X). (X = 4) (reverse works too!)

legs(X, 4), edible(X). (X = cow) X needs to unify to same value for both statements in order to be true, if multiple matches exist, X will match multiple times

Predicates
  temporal
    sequenced results (use match all predicated to print each result)
  spacial
    one result composed of all results

How to stop backtracking (searching for more possible results)
  use cut! ("!")
  more efficient but changes meaning of code
    predicates also can't go in reverse now

doing math
X is 3+4 (good)
7 is X+4 (bad) (aka can't go backwards)

how to do math backwards? CLPFD module (#operator)
X #= 3+4
10 #= X + 7
uses constraint satisfaction to solve

## Garbage Collection ##
In python
  objects have "marked" flags
  locals / globals become roots in a graph
  Mark & Sweep alg used
  done in another thread (Global interpreter lock required) (GIL)
    not actually concurrent bcs mark & sweep not thread safe

Mark & Sweep
  not thread safe
  causes irregular pauses in execution
  1. start at root and traverse downward the objs it references
  2. mark obj if referenced, (0 and 1 is fine, count not needed)
  3. if any obj at end has 0 marks, get rid of it

Generational Garbage Collection
  motivation is that objects are ususally either very short or long lived
  make generational buckets (young / old) (could have multiple buckets)
  do mark and sweep and keep count of how often object survives
  if survives passed threshold, move to old bucket
  objects in old bucket get marked and swept less frequently then young
  multiple pools with multiple freqs are fine

Concurrent Garabaje Collection (White Grey Black) *thread safe!*
  3 stages of objects: white, grey, black
  alg starts w/ init:
    root objects are grey
    non root are white
    new or modified objs moved into grey section

  move all grey objs into black section
  move all objs pointed by black objs to grey
  dealloc all objs in white


## Reference Counting ##
alternate to garbage collection
  less overhead
  cant deal with cicular references (possible to avoid tho)
  clean up at end of function
  using pointers that destruct automatically
    desctructor gets called when var out of scope

smart pointers
  unique pointer - cant be copied (no reference counting needed)
  shared pointer - reference count needed to know when to free obj

shared pointer
  has count for references to obj (count is on heap)
  when we make a copy of our pointer, we inc refernce count
  when count 0, free obj

Borrow Checking in Rust is similar to reference counting
  reference counting -> runtime
  borrow checking -> compile time

  Borrow checking makes sure no references to a value after its destroyed
  borrowed refs cant extend lifetime of owned value
  to return pointer mutable pointer must be used (only 1 mutable pointer to an obj can exist at a time, so when u return, prev is gone new one is returned)
  You can have as many non mutable read only pointers to obj (reference count will be done at compile time on obj)
  
